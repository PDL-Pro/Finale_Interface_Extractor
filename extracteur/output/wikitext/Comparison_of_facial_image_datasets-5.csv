Dataset Name ; Brief description ; Preprocessing ; Instances ; Format ; Default Task ; Created (updated) ; Reference ;Creator  
Density functional theory quantum simulations of graphene ;Labelled images of raw input to a simulation of graphene ;Raw data (in HDF5 format) and output labels from density functional theory quantum simulation ; 60744 test and 501473 and training files ;Labeled images ;Regression ;2019 ; publisher=National Research Council of Canada ;K. Mills & I. Tamblyn  
Quantum simulations of an electron in a two dimensional potential well ;Labelled images of raw input to a simulation of 2d Quantum mechanics ;Raw data (in HDF5 format) and output labels from quantum simulation ;1.3 million images ;Labeled images ;Regression ;2017 ; publisher=National Research Council of Canada ;K. Mills, M.A. Spanner, & I. Tamblyn  
MPII Cooking Activities Dataset ;Videos and images of various cooking activities. ;Activity paths and directions, labels, fine-grained motion labeling, activity class, still image extraction and labeling. ;881,755 frames ;Labeled video, images, text ;Classification ;2012 ;Rohrbach, Marcus, et al. "A database for fine grained activity detection of cooking activities."Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on. IEEE, 2012.Kuehne, Hilde, Ali Arslan, and Thomas Serre. "The language of actions: Recovering the syntax and semantics of goal-directed human activities."Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2014. ;M. Rohrbach et al. 
FAMOS Dataset ;5,000 unique microstructures, all samples have been acquired 3 times with two different cameras. ;Original PNG files, sorted per camera and then per acquisition. MATLAB datafiles with one 16384 times 5000 matrix per camera per acquisition. ;30,000 ;Images and .mat files  ;Authentication ;2012 ;Sviatoslav, Voloshynovskiy, et al. "Towards Reproducible results in authentication based on physical non-cloneable functions: The Forensic Authentication Microstructure Optical Set (FAMOS)."Proc. Proceedings of IEEE International Workshop on Information Forensics and Security. 2012. ;S. Voloshynovskiy, et al. 
PharmaPack Dataset ;1,000 unique classes with 54 images per class. ;Class labeling, many local descriptors, like SIFT and aKaZE, and local feature agreators, like Fisher Vector (FV). ;54,000 ;Images and .mat files  ;Fine-grain classification ;2017 ;Olga, Taran and Shideh, Rezaeifar, et al. "PharmaPack: mobile fine-grained recognition of pharma packages."Proc. European Signal Processing Conference (EUSIPCO). 2017. ;O. Taran and S. Rezaeifar, et al. 
Stanford Dogs Dataset ;Images of 120 breeds of dogs from around the world. ;Train/test splits and ImageNet annotations provided. ;20,580 ;Images, text ;Fine-grain classification ;2011 ;Khosla, Aditya, et al. "Novel dataset for fine-grained image categorization: Stanford dogs."Proc. CVPR Workshop on Fine-Grained Visual Categorization (FGVC). 2011.Parkhi, Omkar M., et al. "Cats and dogs."Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on. IEEE, 2012. ;A. Khosla et al. 
StanfordExtra Dataset ;2D keypoints and segmentations for the Stanford Dogs Dataset. ;2D keypoints and segmentations provided. ;12,035 ;Labelled images ;3D reconstruction/pose estimation ;2020 ;Biggs, Benjamin, et al. "Who Left the Dogs Out? 3D Animal Reconstruction with Expectation Maximization in the Loop.."Proc. ECCV. 2020. ;B. Biggs et al. 
The Oxford-IIIT Pet Dataset ;37 categories of pets with roughly 200 images of each. ;Breed labeled, tight bounding box, foreground-background segmentation. ;~ 7,400 ;Images, text ;Classification, object detection ;2012 ;Razavian, Ali, et al. "CNN features off-the-shelf: an astounding baseline for recognition." Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops. 2014. ;O. Parkhi et al. 
Corel Image Features Data Set ;Database of images with features extracted. ;Many features including color histogram, co-occurrence texture, and colormoments, ;68,040 ;Text ;Classification, object detection ;1999 ; citeseerx = 10.1.1.36.6079 He, Xuming, Richard S. Zemel, and Miguel Á. Carreira-Perpiñán. "[ftp://www-vhost.cs.toronto.edu/public_html/public_html/dist/zemel/Papers/cvpr04.pdf Multiscale conditional random fields for image labeling]." Computer vision and pattern recognition, 2004. CVPR 2004. Proceedings of the 2004 IEEE computer society conference on. Vol. 2. IEEE, 2004. ;M. Ortega-Bindenberger et al. 
Online Video Characteristics and Transcoding Time Dataset. ;Transcoding times for various different videos and video properties. ;Video features given. ;168,286 ;Text ;Regression ;2015 ;Deneke, Tewodros, et al. "Video transcoding time prediction for proactive load balancing." Multimedia and Expo (ICME), 2014 IEEE International Conference on. IEEE, 2014. ;T. Deneke et al. 
Microsoft Sequential Image Narrative Dataset (SIND) ;Dataset for sequential vision-to-language ;Descriptive caption and storytelling given for each photo, and photos are arranged in sequences ;81,743 ;Images, text ;Visual storytelling ;2016 ;date=13 April 2016  ;Microsoft Research 
Caltech-UCSD Birds-200-2011 Dataset ;Large dataset of images of birds. ;Part locations for birds, bounding boxes, 312 binary attributes given ;11,788 ;Images, text ;Classification ;2011 ;Wah, Catherine, et al. "The caltech-ucsd birds-200-2011 dataset." (2011).Duan, Kun, et al. "Discovering localized attributes for fine-grained recognition." Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on. IEEE, 2012. ;C. Wah et al. 
YouTube-8M ;Large and diverse labeled video dataset ;YouTube video IDs and associated labels from a diverse vocabulary of 4800 visual entities ;8 million ;Video, text ;Video classification ;2016 ;date=27 September 2016  ;S. Abu-El-Haija et al.  
YFCC100M ;Large and diverse labeled image and video dataset ;Flickr Videos and Images and associated description, titles, tags, and other metadata (such as EXIF and geotags) ;100million ;Video, Image, Text ;Video and Image classification ;2016 ;s2cid=207230134  ;B. Thomee et al. 
Discrete LIRIS-ACCEDE ;Short videos annotated for valence and arousal. ;Valence and arousal labels. ;9800 ;Video ;Video emotion elicitation detection ;2015 ;Y. Baveye, E. Dellandrea, C. Chamaret, and L. Chen, "LIRIS-ACCEDE: A Video Database for Affective Content Analysis,” in IEEE Transactions on Affective Computing, 2015. ;Y. Baveye et al. 
Continuous LIRIS-ACCEDE ;Long videos annotated for valence and arousal while also collecting Galvanic Skin Response. ;Valence and arousal labels. ;30 ;Video ;Video emotion elicitation detection ;2015 ;Y. Baveye, E. Dellandrea, C. Chamaret, and L. Chen, "Deep Learning vs. Kernel Methods: Performance for Emotion Prediction in Videos," in 2015 Humaine Association Conference on Affective Computing and Intelligent Interaction (ACII), 2015. ;Y. Baveye et al. 
MediaEval LIRIS-ACCEDE ;Extension of Discrete LIRIS-ACCEDE including annotations for violence levels of the films. ;Violence, valence and arousal labels. ;10900 ;Video ;Video emotion elicitation detection ;2015 ;M. Sjöberg, Y. Baveye, H. Wang, V. L. Quang, B. Ionescu, E. Dellandréa, M. Schedl, C.-H. Demarty, and L. Chen, "The mediaeval 2015 affective impact of movies task," in MediaEval 2015 Workshop, 2015. ;Y. Baveye et al. 
Leeds Sports Pose ;Articulated human pose annotations in 2000 natural sports images from Flickr. ;Rough crop around single person of interest with 14 joint labels ;2000 ;Images plus .mat file labels ;Human pose estimation ;2010 ;S. Johnson and M. Everingham, "Clustered Pose and Nonlinear Appearance Models for Human Pose Estimation", in Proceedings of the 21st British Machine Vision Conference (BMVC2010) ;S. Johnson and M. Everingham 
Leeds Sports Pose Extended Training ;Articulated human pose annotations in 10,000 natural sports images from Flickr. ;14 joint labels via crowdsourcing ;10000 ;Images plus .mat file labels ;Human pose estimation ;2011 ;S. Johnson and M. Everingham, "Learning Effective Human Pose Estimation from Inaccurate Annotation", In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR2011) ;S. Johnson and M. Everingham 
MCQ Dataset ;6 different real multiple choice-based exams (735 answer sheets and 33,540 answer boxes) to evaluate computer vision techniques and systems developed for multiple choice test assessment systems. ;None ;735 answer sheets and 33,540 answer boxes ;Images and .mat file labels ;Development of multiple choice test assessment systems ;2017 ;class=cs.CV ;Afifi, M. et al. 
Surveillance Videos ;Real surveillance videos cover a large surveillance time (7 days with 24 hours each). ;None ;19 surveillance videos (7 days with 24 hours each). ;Videos ;Data compression ;2016 ;s2cid=8698850 ;Taj-Eddin, I. A. T. F. et al. 
LILA BC ;Labeled Information Library of Alexandria: Biology and Conservation.  Labeled images that support machine learning research around ecology and environmental science. ;None ;~10M images ;Images ;Classification ;2019 ;doi-access=free ;LILA working group 
Can We See Photosynthesis? ;32 videos for eight live and eight dead leaves recorded under both DC and AC lighting conditions.  ;None ;32 videos ;Videos ;Liveness detection of plants ;2017 ;s2cid=12367169 ;Taj-Eddin, I. A. T. F. et al. 
